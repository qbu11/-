接口文档：https://docs.newapi.pro/api/openai-chat/


OpenAI 对话格式（Chat Completions）¶
官方文档
OpenAI Chat
📝 简介¶
给定一组包含对话的消息列表，模型将返回一个响应。相关指南可参阅OpenAI官网：Chat Completions
💡 请求示例¶
基础文本对话 ✅¶
curl https://你的newapi服务器地址/v1/chat/completions \  -H "Content-Type: application/json" \  -H "Authorization: Bearer $NEWAPI_API_KEY" \  -d '{    "model": "gpt-4.1",    "messages": [      {        "role": "developer",        "content": "你是一个有帮助的助手。"      },      {        "role": "user",        "content": "你好！"      }    ]  }'
响应示例:
{  "id": "chatcmpl-B9MBs8CjcvOU2jLn4n570S5qMJKcT",  "object": "chat.completion",  "created": 1741569952,  "model": "gpt-4.1-2025-04-14",  "choices": [    {      "index": 0,      "message": {        "role": "assistant",        "content": "你好！我能为你提供什么帮助？",        "refusal": null,        "annotations": []      },      "logprobs": null,      "finish_reason": "stop"    }  ],  "usage": {    "prompt_tokens": 19,    "completion_tokens": 10,    "total_tokens": 29,    "prompt_tokens_details": {      "cached_tokens": 0,      "audio_tokens": 0    },    "completion_tokens_details": {      "reasoning_tokens": 0,      "audio_tokens": 0,      "accepted_prediction_tokens": 0,      "rejected_prediction_tokens": 0    }  },  "service_tier": "default"}
图像分析对话 ✅¶
curl https://你的newapi服务器地址/v1/chat/completions \  -H "Content-Type: application/json" \  -H "Authorization: Bearer $NEWAPI_API_KEY" \  -d '{    "model": "gpt-4.1",    "messages": [      {        "role": "user",        "content": [          {            "type": "text",            "text": "这张图片里有什么？"          },          {            "type": "image_url",            "image_url": {              "url": "https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg"            }          }        ]      }    ],    "max_tokens": 300  }'
响应示例:
{  "id": "chatcmpl-B9MHDbslfkBeAs8l4bebGdFOJ6PeG",  "object": "chat.completion",  "created": 1741570283,  "model": "gpt-4.1-2025-04-14",  "choices": [    {      "index": 0,      "message": {        "role": "assistant",        "content": "图片展示了一条穿过茂密绿色草地或草甸的木制栈道。天空湛蓝，点缀着几朵散落的云彩，给整个场景营造出宁静祥和的氛围。背景中可以看到树木和灌木丛。",        "refusal": null,        "annotations": []      },      "logprobs": null,      "finish_reason": "stop"    }  ],  "usage": {    "prompt_tokens": 1117,    "completion_tokens": 46,    "total_tokens": 1163,    "prompt_tokens_details": {      "cached_tokens": 0,      "audio_tokens": 0    },    "completion_tokens_details": {      "reasoning_tokens": 0,      "audio_tokens": 0,      "accepted_prediction_tokens": 0,      "rejected_prediction_tokens": 0    }  },  "service_tier": "default",  "system_fingerprint": "fp_fc9f1d7035"}
流式响应 ✅¶
curl https://你的newapi服务器地址/v1/chat/completions \  -H "Content-Type: application/json" \  -H "Authorization: Bearer $NEWAPI_API_KEY" \  -d '{    "model": "gpt-4.1",    "messages": [      {        "role": "developer",        "content": "你是一个有帮助的助手。"      },      {        "role": "user",        "content": "你好！"      }    ],    "stream": true  }'
流式响应示例:
{"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"role":"assistant","content":""},"logprobs":null,"finish_reason":null}]}
{"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{"content":"你好"},"logprobs":null,"finish_reason":null}]}
// ... 更多数据块 ...
{"id":"chatcmpl-123","object":"chat.completion.chunk","created":1694268190,"model":"gpt-4o-mini", "system_fingerprint": "fp_44709d6fcb", "choices":[{"index":0,"delta":{},"logprobs":null,"finish_reason":"stop"}]}
函数调用 ✅¶
curl https://你的newapi服务器地址/v1/chat/completions \  -H "Content-Type: application/json" \  -H "Authorization: Bearer $NEWAPI_API_KEY" \  -d '{    "model": "gpt-4.1",    "messages": [      {        "role": "user",        "content": "波士顿今天的天气怎么样？"      }    ],    "tools": [      {        "type": "function",        "function": {          "name": "get_current_weather",          "description": "获取指定位置的当前天气",          "parameters": {            "type": "object",            "properties": {              "location": {                "type": "string",                "description": "城市和州，例如 San Francisco, CA"              },              "unit": {                "type": "string",                "enum": ["celsius", "fahrenheit"]              }            },            "required": ["location"]          }        }      }    ],    "tool_choice": "auto"  }'
响应示例:
{  "id": "chatcmpl-abc123",  "object": "chat.completion",  "created": 1699896916,  "model": "gpt-4o-mini",  "choices": [    {      "index": 0,      "message": {        "role": "assistant",        "content": null,        "tool_calls": [          {            "id": "call_abc123",            "type": "function",            "function": {              "name": "get_current_weather",              "arguments": "{\n\"location\": \"Boston, MA\"\n}"            }          }        ]      },      "logprobs": null,      "finish_reason": "tool_calls"    }  ],  "usage": {    "prompt_tokens": 82,    "completion_tokens": 17,    "total_tokens": 99,    "completion_tokens_details": {      "reasoning_tokens": 0,      "accepted_prediction_tokens": 0,      "rejected_prediction_tokens": 0    }  }}
Logprobs 请求 ✅¶
curl https://你的newapi服务器地址/v1/chat/completions \  -H "Content-Type: application/json" \  -H "Authorization: Bearer $NEWAPI_API_KEY" \  -d '{    "model": "gpt-4.1",    "messages": [      {        "role": "user",        "content": "你好！"      }    ],    "logprobs": true,    "top_logprobs": 2  }'
响应示例:
{  "id": "chatcmpl-123",  "object": "chat.completion",  "created": 1702685778,  "model": "gpt-4o-mini",  "choices": [    {      "index": 0,      "message": {        "role": "assistant",        "content": "你好！我能为你提供什么帮助？"      },      "logprobs": {        "content": [          {            "token": "Hello",            "logprob": -0.31725305,            "bytes": [72, 101, 108, 108, 111],            "top_logprobs": [              {                "token": "Hello",                "logprob": -0.31725305,                "bytes": [72, 101, 108, 108, 111]              },              {                "token": "Hi",                "logprob": -1.3190403,                "bytes": [72, 105]              }            ]          },          {            "token": "!",            "logprob": -0.02380986,            "bytes": [              33            ],            "top_logprobs": [              {                "token": "!",                "logprob": -0.02380986,                "bytes": [33]              },              {                "token": " there",                "logprob": -3.787621,                "bytes": [32, 116, 104, 101, 114, 101]              }            ]          },          {            "token": " How",            "logprob": -0.000054669687,            "bytes": [32, 72, 111, 119],            "top_logprobs": [              {                "token": " How",                "logprob": -0.000054669687,                "bytes": [32, 72, 111, 119]              },              {                "token": "<|end|>",                "logprob": -10.953937,                "bytes": null              }            ]          },          {            "token": " can",            "logprob": -0.015801601,            "bytes": [32, 99, 97, 110],            "top_logprobs": [              {                "token": " can",                "logprob": -0.015801601,                "bytes": [32, 99, 97, 110]              },              {                "token": " may",                "logprob": -4.161023,                "bytes": [32, 109, 97, 121]              }            ]          },          {            "token": " I",            "logprob": -3.7697225e-6,            "bytes": [              32,              73            ],            "top_logprobs": [              {                "token": " I",                "logprob": -3.7697225e-6,                "bytes": [32, 73]              },              {                "token": " assist",                "logprob": -13.596657,                "bytes": [32, 97, 115, 115, 105, 115, 116]              }            ]          },          {            "token": " assist",            "logprob": -0.04571125,            "bytes": [32, 97, 115, 115, 105, 115, 116],            "top_logprobs": [              {                "token": " assist",                "logprob": -0.04571125,                "bytes": [32, 97, 115, 115, 105, 115, 116]              },              {                "token": " help",                "logprob": -3.1089056,                "bytes": [32, 104, 101, 108, 112]              }            ]          },          {            "token": " you",            "logprob": -5.4385737e-6,            "bytes": [32, 121, 111, 117],            "top_logprobs": [              {                "token": " you",                "logprob": -5.4385737e-6,                "bytes": [32, 121, 111, 117]              },              {                "token": " today",                "logprob": -12.807695,                "bytes": [32, 116, 111, 100, 97, 121]              }            ]          },          {            "token": " today",            "logprob": -0.0040071653,            "bytes": [32, 116, 111, 100, 97, 121],            "top_logprobs": [              {                "token": " today",                "logprob": -0.0040071653,                "bytes": [32, 116, 111, 100, 97, 121]              },              {                "token": "?",                "logprob": -5.5247097,                "bytes": [63]              }            ]          },          {            "token": "?",            "logprob": -0.0008108172,            "bytes": [63],            "top_logprobs": [              {                "token": "?",                "logprob": -0.0008108172,                "bytes": [63]              },              {                "token": "?\n",                "logprob": -7.184561,                "bytes": [63, 10]              }            ]          }        ]      },      "finish_reason": "stop"    }  ],  "usage": {    "prompt_tokens": 9,    "completion_tokens": 9,    "total_tokens": 18,    "completion_tokens_details": {      "reasoning_tokens": 0,      "accepted_prediction_tokens": 0,      "rejected_prediction_tokens": 0    }  },  "system_fingerprint": null}
📮 请求¶
端点¶
POST /v1/chat/completions
创建给定聊天对话的模型响应。更多详情请参阅文本生成、视觉和音频指南。
鉴权方法¶
在请求头中包含以下内容进行 API 密钥认证：
Authorization: Bearer $NEWAPI_API_KEY
其中 $NEWAPI_API_KEY 是您的 API 密钥。您可以在 OpenAI 平台的 API 密钥页面中找到或生成 API 密钥。
请求体参数¶
messages¶
- 类型：数组
- 必需：是
到目前为止包含对话的消息列表。根据使用的模型，支持不同的消息类型（形式），如文本、图像和音频。
暂时无法在飞书文档外展示此内容
Developer message 属性：
暂时无法在飞书文档外展示此内容
System message 属性：
暂时无法在飞书文档外展示此内容
User message 属性：
暂时无法在飞书文档外展示此内容
内容部分类型：
暂时无法在飞书文档外展示此内容
文本内容部分属性：
暂时无法在飞书文档外展示此内容
图像内容部分属性：
暂时无法在飞书文档外展示此内容
图像URL对象属性：
暂时无法在飞书文档外展示此内容
音频内容部分属性：
暂时无法在飞书文档外展示此内容
音频输入对象属性：
暂时无法在飞书文档外展示此内容
文件内容部分属性：
暂时无法在飞书文档外展示此内容
文件对象属性：
暂时无法在飞书文档外展示此内容
Assistant message 属性：
暂时无法在飞书文档外展示此内容
Tool message 属性：
暂时无法在飞书文档外展示此内容
Function message 属性：（已弃用）
暂时无法在飞书文档外展示此内容
model¶
- 类型：字符串
- 必需：是
要使用的模型 ID。有关哪些模型适用于 Chat API 的详细信息，请参阅模型端点兼容性表。
store¶
- 类型：布尔值或 null
- 必需：否
- 默认值：false
是否存储此聊天补全请求的输出以用于我们的模型蒸馏或评估产品。
reasoning_effort¶
- 类型：字符串或 null
- 必需：否
- 默认值：medium
- 仅适用于 o系列 的模型
约束推理模型的推理工作。当前支持的值为 low、medium 和 high。减少推理工作可以加快响应速度并减少响应中用于推理的标记数。
metadata¶
- 类型：map
- 必需：否
可以附加到对象的16个键值对集合。这对于以结构化格式存储对象的其他信息很有用,并可以通过 API 或仪表板查询对象。
键是最大长度为64个字符的字符串。值是最大长度为512个字符的字符串。
modalities¶
- 类型：数组或 null
- 必需：否
您希望模型为此请求生成的输出类型。大多数模型都能生成文本,这是默认设置: ["text"]
该模型还可以用于生成音频。要请求此模型同时生成文本和音频响应,您可以使用: ["text", "audio"]
prediction¶
- 类型：对象
- 必需：否
预测输出的配置,当提前知道模型响应的大部分内容时,可以大大提高响应时间。这在您只对文件进行微小更改时最常见。
可能的类型：
暂时无法在飞书文档外展示此内容
静态内容属性：
暂时无法在飞书文档外展示此内容
内容可能的类型：
1. 文本内容（字符串） - 用于预测输出的内容。这通常是您正在重新生成的文件的文本，只有微小更改。
2. 内容部分数组（数组） - 具有定义类型的内容部分数组。支持的选项因用于生成响应的模型而异。可以包含文本输入。
内容部分数组属性：
暂时无法在飞书文档外展示此内容
audio¶
- 类型：对象或 null
- 必需：否
音频输出的参数。当使用 modalities: ["audio"] 请求音频输出时需要。
暂时无法在飞书文档外展示此内容
temperature¶
- 类型：数字或 null
- 必需：否
- 默认值：1
要使用的采样温度，介于 0 和 2 之间。较高的值（如0.8）会使输出更加随机，而较低的值（如0.2）会使其更加集中和确定性。我们通常建议更改此值或 top_p，但不要同时更改。
top_p¶
- 类型：数字或 null
- 必需：否
- 默认值：1
一种替代采样温度的方法，称为核采样，其中模型考虑具有 top_p 概率质量的标记结果。因此，0.1 意味着只考虑包含前 10% 概率质量的标记。
我们通常建议更改此值或 temperature，但不要同时更改。
n¶
- 类型：整数或 null
- 必需：否
- 默认值：1
为每个输入消息生成多少个聊天补全选择。请注意，您将根据所有选择生成的标记数量收费。保持 n 为 1 可最大限度地降低成本。
stop¶
- 类型：字符串/数组/null
- 必需：否
- 默认值：null
- 不支持最新的推理模型和 .o3、o4-mini
API 将停止生成更多标记的最多 4 个序列。返回的文本不会包含停止序列。
max_tokens¶
- 类型：整数或 null
- 必需：否
聊天补全中可以生成的最大标记数。此值可用于控制通过 API 生成的文本成本。
该值现已弃用，取而代之的是 max_completion_tokens，并且与 o1 系列模型不兼容。
max_completion_tokens¶
- 类型：整数或 null
- 必需：否
补全中可以生成的标记数的上限，包括可见输出标记和推理标记。
presence_penalty¶
- 类型：数字或 null
- 必需：否
- 默认值：0
介于 -2.0 和 2.0 之间的数字。正值根据新标记到目前为止在文本中出现的情况来惩罚它们，从而增加模型讨论新主题的可能性。
frequency_penalty¶
- 类型：数字或 null
- 必需：否
- 默认值：0
介于 -2.0 和 2.0 之间的数字。正值根据新标记到目前为止在文本中的现有频率来惩罚它们，从而降低模型逐字重复同一行的可能性。
logit_bias¶
- 类型：map
- 必需：否
- 默认值：null
修改指定标记出现在补全中的可能性。
接受一个 JSON 对象，该对象将标记（由分词器中的标记 ID 指定）映射到从 -100 到 100 的关联偏差值。在数学上，偏差被添加到模型在采样之前生成的对数中。确切的效果会因模型而异，但介于 -1 和 1 之间的值应该会减少或增加选择的可能性；像 -100 或 100 这样的值应该导致相关标记被禁止或独占选择。
logprobs¶
- 类型：布尔值或 null
- 必需：否
- 默认值：false
是否返回输出标记的对数概率。如果为 true，则返回 message.content 中每个输出标记的对数概率。
user¶
- 类型：字符串
- 必需：否
表示最终用户的唯一标识符，可以帮助 OpenAI 监控和检测滥用行为。了解更多。
service_tier¶
- 类型：字符串或 null
- 必需：否
- 默认值：auto
指定用于处理请求的延迟层级。此参数与订阅了 scale tier 服务的客户相关：
- 如果设置为 'auto'，且项目启用了 Scale tier，系统将使用 scale tier 信用直到用完
- 如果设置为 'auto'，且项目未启用 Scale tier，请求将使用默认服务层级处理，具有较低的正常运行时间 SLA 且无延迟保证
- 如果设置为 'default'，请求将使用默认服务层级处理，具有较低的正常运行时间 SLA 且无延迟保证
- 如果设置为 'flex'，请求将使用 Flex Processing 服务层级处理。详情请参阅文档。
- 未设置时，默认行为为 'auto'
- 当设置此参数时，响应体将包含使用的 service_tier
stream_options¶
- 类型：对象或 null
- 必需：否
- 默认值：null
流式响应的选项。仅在设置 stream: true 时使用。
可能的属性：
暂时无法在飞书文档外展示此内容
response_format¶
- 类型：对象
- 必需：否
指定模型必须输出的格式。
- 设置为 { "type": "json_schema", "json_schema": {...} } 启用结构化输出，确保模型将匹配您提供的 JSON schema。
- 设置为 { "type": "json_object" } 启用 JSON 模式，确保模型生成的消息是有效的 JSON。
重要提示：使用 JSON 模式时，您还必须通过系统或用户消息自行指示模型生成 JSON。否则，模型可能会生成无尽的空白直到生成达到令牌限制。
可能的类型：
暂时无法在飞书文档外展示此内容
text 属性：
暂时无法在飞书文档外展示此内容
json_schema 属性：
暂时无法在飞书文档外展示此内容
json_schema.json_schema 属性：
暂时无法在飞书文档外展示此内容
json_object 属性：
暂时无法在飞书文档外展示此内容
seed¶
- 类型：整数或 null
- 必需：否 Beta 功能。如果指定，我们的系统将尽最大努力进行确定性采样，使得具有相同 seed 和参数的重复请求应返回相同的结果。不保证确定性，您应参考响应参数的 system_fingerprint 以监控后端的变化。
tools¶
- 类型：数组
- 必需：否
模型可能调用的工具列表。目前仅支持函数作为工具。使用此参数提供模型可能生成 JSON 输入的函数列表。最多支持 128 个函数。
属性：
暂时无法在飞书文档外展示此内容
function 属性：
暂时无法在飞书文档外展示此内容
functions¶
- 类型：数组
- 必需：否
- 注意：已弃用，推荐使用 tools
模型可能生成 JSON 输入的函数列表。
暂时无法在飞书文档外展示此内容
tool_choice¶
- 类型：字符串或对象
- 必需：否
控制模型调用哪个工具（如果有）： - none：模型不会调用任何工具，而是生成消息 - auto：模型可以在生成消息或调用一个或多个工具之间选择 - required：模型必须调用一个或多个工具 - {"type": "function", "function": {"name": "my_function"}}：强制模型调用特定工具
当没有工具时默认为 none，有工具时默认为 auto。
可能的类型：
暂时无法在飞书文档外展示此内容
对象属性：
暂时无法在飞书文档外展示此内容
function 属性：
暂时无法在飞书文档外展示此内容
function_call¶
- 类型：字符串或对象
- 必需：否
- 默认值：没有函数时为 none，有函数时为 auto
- 注意：已弃用，推荐使用 tool_choice
控制模型调用哪个函数（如果有）：
- none：模型不会调用函数，而是生成消息
- auto：模型可以在生成消息或调用函数之间选择
- {"name": "my_function"}：强制模型调用特定函数
对象类型属性：
暂时无法在飞书文档外展示此内容
parallel_tool_calls¶
- 类型：布尔值
- 必需：否
- 默认值：true
是否在工具使用期间启用并行函数调用。
stream¶
- 类型：布尔值或 null
- 必需：否
- 默认值：false
如果设置为 true，模型响应数据将在生成时通过服务器发送事件流式传输到客户端。请参阅下方的流式响应部分获取更多信息，以及流式响应指南了解如何处理流式事件。
top_logprobs¶
- 类型：整数或 null
- 必需：否
0 到 20 之间的整数，指定在每个标记位置返回的最可能标记的数量，每个标记都有关联的对数概率。如果使用此参数，必须将 logprobs 设置为 true。
web_search_options¶
- 类型：对象
- 必需：否
此工具搜索网络以获取相关结果用于回复。了解更多关于网络搜索工具的信息。
可能的属性：
暂时无法在飞书文档外展示此内容
user_location 属性：
暂时无法在飞书文档外展示此内容
approximate 属性：
暂时无法在飞书文档外展示此内容